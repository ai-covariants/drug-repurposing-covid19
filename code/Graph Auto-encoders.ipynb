{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNe3m7NKFC/VObSmB7RQReX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F2H1QVEAgeQI","executionInfo":{"status":"ok","timestamp":1666149931111,"user_tz":-660,"elapsed":30758,"user":{"displayName":"Chaarvi Bansal","userId":"11473149911906912928"}},"outputId":"3246fb07-930f-432e-f554-ceb29429d6df"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["from __future__ import division\n","from __future__ import print_function\n","import tensorflow.compat.v1 as tf\n","import numpy as np\n","import scipy.sparse as sp\n","import time\n","import pandas as pd\n","import os\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import average_precision_score\n","import warnings\n","\n","warnings.filterwarnings('ignore')\n","tf.compat.v1.disable_eager_execution()"],"metadata":{"id":"42Qkzr6ziZAS","executionInfo":{"status":"ok","timestamp":1666149939219,"user_tz":-660,"elapsed":4587,"user":{"displayName":"Chaarvi Bansal","userId":"11473149911906912928"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def weight_variable_glorot(input_dim, output_dim, name=\"\"):\n","    \"\"\"Create a weight variable with Glorot & Bengio (AISTATS 2010)\n","    initialization.\n","    \"\"\"\n","    init_range = np.sqrt(6.0 / (input_dim + output_dim))\n","    initial = tf.random_uniform([input_dim, output_dim], minval=-init_range,\n","                                maxval=init_range, dtype=tf.float32)\n","    return tf.Variable(initial, name=name)"],"metadata":{"id":"D6d6lZYVdTJR","executionInfo":{"status":"ok","timestamp":1666149942945,"user_tz":-660,"elapsed":308,"user":{"displayName":"Chaarvi Bansal","userId":"11473149911906912928"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# global unique layer ID dictionary for layer name assignment\n","_LAYER_UIDS = {}\n","def get_layer_uid(layer_name=''):\n","    \"\"\"Helper function, assigns unique layer IDs\n","    \"\"\"\n","    if layer_name not in _LAYER_UIDS:\n","        _LAYER_UIDS[layer_name] = 1\n","        return 1\n","    else:\n","        _LAYER_UIDS[layer_name] += 1\n","        return _LAYER_UIDS[layer_name]\n","def dropout_sparse(x, keep_prob, num_nonzero_elems):\n","    \"\"\"Dropout for sparse tensors. Currently fails for very large sparse tensors (>1M elements)\n","    \"\"\"\n","    noise_shape = [num_nonzero_elems]\n","    random_tensor = keep_prob\n","    random_tensor += tf.random_uniform(noise_shape)\n","    dropout_mask = tf.cast(tf.floor(random_tensor), dtype=tf.bool)\n","    pre_out = tf.sparse_retain(x, dropout_mask)\n","    return pre_out * (1./keep_prob)\n","class Layer(object):\n","    \"\"\"Base layer class. Defines basic API for all layer objects.\n","    # Properties\n","        name: String, defines the variable scope of the layer.\n","    # Methods\n","        _call(inputs): Defines computation graph of layer\n","            (i.e. takes input, returns output)\n","        __call__(inputs): Wrapper for _call()\n","    \"\"\"\n","    def __init__(self, **kwargs):\n","        allowed_kwargs = {'name', 'logging'}\n","        for kwarg in kwargs.keys():\n","            assert kwarg in allowed_kwargs, 'Invalid keyword argument: ' + kwarg\n","        name = kwargs.get('name')\n","        if not name:\n","            layer = self.__class__.__name__.lower()\n","            name = layer + '_' + str(get_layer_uid(layer))\n","        self.name = name\n","        self.vars = {}\n","        logging = kwargs.get('logging', False)\n","        self.logging = logging\n","        self.issparse = False\n","\n","    def _call(self, inputs):\n","        return inputs\n","\n","    def __call__(self, inputs):\n","        with tf.name_scope(self.name):\n","            outputs = self._call(inputs)\n","            return outputs\n","\n","class GraphConvolution(Layer):\n","    \"\"\"Basic graph convolution layer for undirected graph without edge labels.\"\"\"\n","    def __init__(self, input_dim, output_dim, adj, dropout=0., act=tf.nn.relu, **kwargs):\n","        super(GraphConvolution, self).__init__(**kwargs)\n","        with tf.variable_scope(self.name + '_vars'):\n","            self.vars['weights'] = weight_variable_glorot(input_dim, output_dim, name=\"weights\")\n","        self.dropout = dropout\n","        self.adj = adj\n","        self.act = act\n","\n","    def _call(self, inputs):\n","        x = inputs\n","        x = tf.nn.dropout(x, 1-self.dropout)\n","        x = tf.matmul(x, self.vars['weights'])\n","        x = tf.sparse_tensor_dense_matmul(self.adj, x)\n","        outputs = self.act(x)\n","        return outputs\n","class GraphConvolutionSparse(Layer):\n","    \"\"\"Graph convolution layer for sparse inputs.\"\"\"\n","    def __init__(self, input_dim, output_dim, adj, features_nonzero, dropout=0., act=tf.nn.relu, **kwargs):\n","        super(GraphConvolutionSparse, self).__init__(**kwargs)\n","        with tf.variable_scope(self.name + '_vars'):\n","            self.vars['weights'] = weight_variable_glorot(input_dim, output_dim, name=\"weights\")\n","        self.dropout = dropout\n","        self.adj = adj\n","        self.act = act\n","        self.issparse = True\n","        self.features_nonzero = features_nonzero\n","\n","    def _call(self, inputs):\n","        x = inputs\n","        x = dropout_sparse(x, 1-self.dropout, self.features_nonzero)\n","        x = tf.sparse_tensor_dense_matmul(x, self.vars['weights'])\n","        x = tf.sparse_tensor_dense_matmul(self.adj, x)\n","        outputs = self.act(x)\n","        return outputs\n","class InnerProductDecoder(Layer):\n","    \"\"\"Decoder model layer for link prediction.\"\"\"\n","    def __init__(self, input_dim, dropout=0., act=tf.nn.sigmoid, **kwargs):\n","        super(InnerProductDecoder, self).__init__(**kwargs)\n","        self.dropout = dropout\n","        self.act = act\n","\n","    def _call(self, inputs):\n","        inputs = tf.nn.dropout(inputs, 1-self.dropout)\n","        x = tf.transpose(inputs)\n","        x = tf.matmul(inputs, x)\n","        x = tf.reshape(x, [-1])\n","        outputs = self.act(x)\n","        return outputs"],"metadata":{"id":"PU-sY15ydWcF","executionInfo":{"status":"ok","timestamp":1666149944173,"user_tz":-660,"elapsed":4,"user":{"displayName":"Chaarvi Bansal","userId":"11473149911906912928"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["class Model(object):\n","    def __init__(self, **kwargs):\n","        allowed_kwargs = {'name', 'logging'}\n","        for kwarg in kwargs.keys():\n","            assert kwarg in allowed_kwargs, 'Invalid keyword argument: ' + kwarg\n","\n","        for kwarg in kwargs.keys():\n","            assert kwarg in allowed_kwargs, 'Invalid keyword argument: ' + kwarg\n","        name = kwargs.get('name')\n","        if not name:\n","            name = self.__class__.__name__.lower()\n","        self.name = name\n","\n","        logging = kwargs.get('logging', False)\n","        self.logging = logging\n","\n","        self.vars = {}\n","\n","    def _build(self):\n","        raise NotImplementedError\n","\n","    def build(self):\n","        \"\"\" Wrapper for _build() \"\"\"\n","        with tf.variable_scope(self.name):\n","            self._build()\n","        variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=self.name)\n","        self.vars = {var.name: var for var in variables}\n","\n","    def fit(self):\n","        pass\n","\n","    def predict(self):\n","        pass\n","\n","class GCNModelAE(Model):\n","    def __init__(self, placeholders, num_features, features_nonzero, **kwargs):\n","        super(GCNModelAE, self).__init__(**kwargs)\n","\n","        self.inputs = placeholders['features']\n","        self.input_dim = num_features\n","        self.features_nonzero = features_nonzero\n","        self.adj = placeholders['adj']\n","        self.dropout = placeholders['dropout']\n","        self.build()\n","\n","    def _build(self):\n","        self.hidden1 = GraphConvolutionSparse(input_dim=self.input_dim,\n","                                              output_dim=32,\n","                                              adj=self.adj,\n","                                              features_nonzero=self.features_nonzero,\n","                                              act=tf.nn.relu,\n","                                              dropout=self.dropout,\n","                                              logging=self.logging)(self.inputs)\n","\n","        self.embeddings = GraphConvolution(input_dim=32,\n","                                           output_dim=8,\n","                                           adj=self.adj,\n","                                           act=lambda x: x,\n","                                           dropout=self.dropout,\n","                                           logging=self.logging)(self.hidden1)\n","\n","        self.z_mean = self.embeddings\n","\n","        self.reconstructions = InnerProductDecoder(input_dim=8,\n","                                      act=lambda x: x,\n","                                      logging=self.logging)(self.embeddings)"],"metadata":{"id":"3wy9xu_7de--","executionInfo":{"status":"ok","timestamp":1666150431477,"user_tz":-660,"elapsed":262,"user":{"displayName":"Chaarvi Bansal","userId":"11473149911906912928"}}},"execution_count":81,"outputs":[]},{"cell_type":"code","source":["class OptimizerAE(object):\n","    def __init__(self, preds, labels, pos_weight, norm):\n","        preds_sub = preds\n","        labels_sub = labels\n","\n","        self.cost = norm * tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(logits=preds_sub, targets=labels_sub, pos_weight=pos_weight))\n","        self.optimizer = tf.train.AdamOptimizer(learning_rate=0.01)  # Adam Optimizer\n","\n","        self.opt_op = self.optimizer.minimize(self.cost)\n","        self.grads_vars = self.optimizer.compute_gradients(self.cost)\n","\n","        self.correct_prediction = tf.equal(tf.cast(tf.greater_equal(tf.sigmoid(preds_sub), 0.5), tf.int32),\n","                                           tf.cast(labels_sub, tf.int32))\n","        self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))"],"metadata":{"id":"9lULmLcpdoJA","executionInfo":{"status":"ok","timestamp":1666150431788,"user_tz":-660,"elapsed":4,"user":{"displayName":"Chaarvi Bansal","userId":"11473149911906912928"}}},"execution_count":82,"outputs":[]},{"cell_type":"code","source":["def sparse_to_tuple(sparse_mx):\n","    if not sp.isspmatrix_coo(sparse_mx):\n","        sparse_mx = sparse_mx.tocoo()\n","    coords = np.vstack((sparse_mx.row, sparse_mx.col)).transpose()\n","    values = sparse_mx.data\n","    shape = sparse_mx.shape\n","    return coords, values, shape\n","\n","\n","def preprocess_graph(adj):\n","    adj = sp.coo_matrix(adj)\n","    adj_ = adj + sp.eye(adj.shape[0])\n","    rowsum = np.array(adj_.sum(1))\n","    degree_mat_inv_sqrt = sp.diags(np.power(rowsum, -0.5).flatten())\n","    adj_normalized = adj_.dot(degree_mat_inv_sqrt).transpose().dot(degree_mat_inv_sqrt).tocoo()\n","    return sparse_to_tuple(adj_normalized)\n","\n","\n","def construct_feed_dict(adj_normalized, adj, features, placeholders):\n","    # construct feed dictionary\n","    feed_dict = dict()\n","    feed_dict.update({placeholders['features']: features})\n","    feed_dict.update({placeholders['adj']: adj_normalized})\n","    feed_dict.update({placeholders['adj_orig']: adj})\n","    return feed_dict\n","\n","\n","def mask_test_edges(adj):\n","    # Function to build test set with 10% positive links\n","    # NOTE: Splits are randomized and results might slightly deviate from reported numbers in the paper.\n","    # TODO: Clean up.\n","\n","    # Remove diagonal elements\n","    adj = adj - sp.dia_matrix((adj.diagonal()[np.newaxis, :], [0]), shape=adj.shape)\n","    adj.eliminate_zeros()\n","    # Check that diag is zero:\n","    assert np.diag(adj.todense()).sum() == 0\n","\n","    adj_triu = sp.triu(adj)\n","    adj_tuple = sparse_to_tuple(adj_triu)\n","    edges = adj_tuple[0]\n","    edges_all = sparse_to_tuple(adj)[0]\n","    num_test = int(np.floor(edges.shape[0] / 10.))\n","    num_val = int(np.floor(edges.shape[0] / 20.))\n","\n","    all_edge_idx = list(range(edges.shape[0]))\n","    np.random.shuffle(all_edge_idx)\n","    val_edge_idx = all_edge_idx[:num_val]\n","    test_edge_idx = all_edge_idx[num_val:(num_val + num_test)]\n","    test_edges = edges[test_edge_idx]\n","    val_edges = edges[val_edge_idx]\n","    train_edges = np.delete(edges, np.hstack([test_edge_idx, val_edge_idx]), axis=0)\n","\n","    def ismember(a, b, tol=5):\n","        rows_close = np.all(np.round(a - b[:, None], tol) == 0, axis=-1)\n","        return np.any(rows_close)\n","\n","    test_edges_false = []\n","    while len(test_edges_false) < len(test_edges):\n","        idx_i = np.random.randint(0, adj.shape[0])\n","        idx_j = np.random.randint(0, adj.shape[0])\n","        if idx_i == idx_j:\n","            continue\n","        if ismember([idx_i, idx_j], edges_all):\n","            continue\n","        if test_edges_false:\n","            if ismember([idx_j, idx_i], np.array(test_edges_false)):\n","                continue\n","            if ismember([idx_i, idx_j], np.array(test_edges_false)):\n","                continue\n","        test_edges_false.append([idx_i, idx_j])\n","\n","    val_edges_false = []\n","    while len(val_edges_false) < len(val_edges):\n","        idx_i = np.random.randint(0, adj.shape[0])\n","        idx_j = np.random.randint(0, adj.shape[0])\n","        if idx_i == idx_j:\n","            continue\n","        if ismember([idx_i, idx_j], train_edges):\n","            continue\n","        if ismember([idx_j, idx_i], train_edges):\n","            continue\n","        if ismember([idx_i, idx_j], val_edges):\n","            continue\n","        if ismember([idx_j, idx_i], val_edges):\n","            continue\n","        if val_edges_false:\n","            if ismember([idx_j, idx_i], np.array(val_edges_false)):\n","                continue\n","            if ismember([idx_i, idx_j], np.array(val_edges_false)):\n","                continue\n","        val_edges_false.append([idx_i, idx_j])\n","\n","    #assert ~ismember(test_edges_false, edges_all)\n","    #assert ~ismember(val_edges_false, edges_all)\n","    #assert ~ismember(val_edges, train_edges)\n","    #assert ~ismember(test_edges, train_edges)\n","    #assert ~ismember(val_edges, test_edges)\n","\n","    data = np.ones(train_edges.shape[0])\n","\n","    # Re-build adj matrix\n","    adj_train = sp.csr_matrix((data, (train_edges[:, 0], train_edges[:, 1])), shape=adj.shape)\n","    adj_train = adj_train + adj_train.T\n","\n","    # NOTE: these edge lists only contain single direction of edge!\n","    return adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false"],"metadata":{"id":"QLF6j8X7dtf-","executionInfo":{"status":"ok","timestamp":1666150432206,"user_tz":-660,"elapsed":4,"user":{"displayName":"Chaarvi Bansal","userId":"11473149911906912928"}}},"execution_count":83,"outputs":[]},{"cell_type":"code","source":["# Load data\n","adj = pd.read_csv('/content/drive/MyDrive/Thesis_5_1/data/DDR-CT.csv')\n","features = pd.read_csv('/content/drive/MyDrive/Thesis_5_1/data/with clinical trial drugs/all_drug_data_processed.csv')"],"metadata":{"id":"HlHWXpDAeKlT","executionInfo":{"status":"ok","timestamp":1666150432955,"user_tz":-660,"elapsed":457,"user":{"displayName":"Chaarvi Bansal","userId":"11473149911906912928"}}},"execution_count":84,"outputs":[]},{"cell_type":"code","source":["#feature_matrix = feature_matrix.drop('Unnamed: 0',axis=1)\n","features.set_index('Name',inplace=True)\n","adj.set_index('Unnamed: 0', inplace=True)"],"metadata":{"id":"vXLdyqodjaJb","executionInfo":{"status":"ok","timestamp":1666150433386,"user_tz":-660,"elapsed":1,"user":{"displayName":"Chaarvi Bansal","userId":"11473149911906912928"}}},"execution_count":85,"outputs":[]},{"cell_type":"code","source":["features = sp.csr_matrix(features.astype(pd.SparseDtype(\"float64\",0)).sparse.to_coo())\n","adj = sp.csr_matrix(adj.astype(pd.SparseDtype(\"float64\",0)))"],"metadata":{"id":"VenC_Ikgjhw3","executionInfo":{"status":"ok","timestamp":1666150433641,"user_tz":-660,"elapsed":256,"user":{"displayName":"Chaarvi Bansal","userId":"11473149911906912928"}}},"execution_count":86,"outputs":[]},{"cell_type":"code","source":["# Store original adjacency matrix (without diagonal entries) for later\n","adj_orig = adj\n","adj_orig = adj_orig - sp.dia_matrix((adj_orig.diagonal()[np.newaxis, :], [0]), shape=adj_orig.shape)\n","adj_orig.eliminate_zeros()\n","\n","adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false = mask_test_edges(adj)\n","adj = adj_train\n","\n","# Some preprocessing\n","adj_norm = preprocess_graph(adj)\n","\n","# Define placeholders\n","placeholders = {\n","    'features': tf.sparse_placeholder(tf.float32),\n","    'adj': tf.sparse_placeholder(tf.float32),\n","    'adj_orig': tf.sparse_placeholder(tf.float32),\n","    'dropout': tf.placeholder_with_default(0., shape=())\n","}\n","\n","num_nodes = adj.shape[0]\n","\n","features = sparse_to_tuple(features.tocoo())\n","num_features = features[2][1]\n","features_nonzero = features[1].shape[0]"],"metadata":{"id":"97CStYwKeObQ","executionInfo":{"status":"ok","timestamp":1666150434891,"user_tz":-660,"elapsed":1253,"user":{"displayName":"Chaarvi Bansal","userId":"11473149911906912928"}}},"execution_count":87,"outputs":[]},{"cell_type":"code","source":["# Create model\n","model = None\n","model = GCNModelAE(placeholders, num_features, features_nonzero)\n","pos_weight = float(adj.shape[0] * adj.shape[0] - adj.sum()) / adj.sum()\n","norm = adj.shape[0] * adj.shape[0] / float((adj.shape[0] * adj.shape[0] - adj.sum()) * 2)\n","\n","# Optimizer\n","with tf.name_scope('optimizer'):\n","  opt = OptimizerAE(preds=model.reconstructions,labels=tf.reshape(tf.sparse_tensor_to_dense(placeholders['adj_orig'],validate_indices=False), [-1]),pos_weight=pos_weight,norm=norm)"],"metadata":{"id":"4WOVNBmOeUMa","executionInfo":{"status":"ok","timestamp":1666150435175,"user_tz":-660,"elapsed":288,"user":{"displayName":"Chaarvi Bansal","userId":"11473149911906912928"}}},"execution_count":88,"outputs":[]},{"cell_type":"code","source":["# Initialize session\n","sess = tf.Session()\n","sess.run(tf.global_variables_initializer())\n","\n","cost_val = []\n","acc_val = []\n","def get_roc_score(edges_pos, edges_neg, emb=None):\n","    if emb is None:\n","        feed_dict.update({placeholders['dropout']: 0})\n","        emb = sess.run(model.z_mean, feed_dict=feed_dict)\n","\n","    def sigmoid(x):\n","        return 1 / (1 + np.exp(-x))\n","\n","    # Predict on test set of edges\n","    adj_rec = np.dot(emb, emb.T)\n","    preds = []\n","    pos = []\n","    for e in edges_pos:\n","        preds.append(sigmoid(adj_rec[e[0], e[1]]))\n","        pos.append(adj_orig[e[0], e[1]])\n","\n","    preds_neg = []\n","    neg = []\n","    for e in edges_neg:\n","        preds_neg.append(sigmoid(adj_rec[e[0], e[1]]))\n","        neg.append(adj_orig[e[0], e[1]])\n","\n","    preds_all = np.hstack([preds, preds_neg])\n","    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds_neg))])\n","    roc_score = roc_auc_score(labels_all, preds_all)\n","    ap_score = average_precision_score(labels_all, preds_all)\n","\n","    return roc_score, ap_score"],"metadata":{"id":"6MZgZ7sHeYTS","executionInfo":{"status":"ok","timestamp":1666150435442,"user_tz":-660,"elapsed":268,"user":{"displayName":"Chaarvi Bansal","userId":"11473149911906912928"}}},"execution_count":89,"outputs":[]},{"cell_type":"code","source":["cost_val = []\n","acc_val = []\n","val_roc_score = []\n","\n","adj_label = adj_train + sp.eye(adj_train.shape[0])\n","adj_label = sparse_to_tuple(adj_label)\n","\n","# Train model\n","for epoch in range(200):\n","\n","    t = time.time()\n","    # Construct feed dictionary\n","    feed_dict = construct_feed_dict(adj_norm, adj_label, features, placeholders)\n","    feed_dict.update({placeholders['dropout']: 0.})\n","    # Run single weight update\n","    outs = sess.run([opt.opt_op, opt.cost, opt.accuracy], feed_dict=feed_dict)\n","\n","    # Compute average loss\n","    avg_cost = outs[1]\n","    avg_accuracy = outs[2]\n","\n","    #roc_curr, ap_curr = get_roc_score(val_edges, val_edges_false)\n","    #val_roc_score.append(roc_curr)\n","\n","    print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(avg_cost),\n","          \"train_acc=\", \"{:.5f}\".format(avg_accuracy),\n","          \"time=\", \"{:.5f}\".format(time.time() - t))\n","\n","print(\"Optimization Finished!\")\n","emb = sess.run(model.z_mean, feed_dict = feed_dict)\n","#roc_score, ap_score = get_roc_score(test_edges, test_edges_false)\n","#print('Test ROC score: ' + str(roc_score))\n","#print('Test AP score: ' + str(ap_score))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9BF3f7oje6dv","executionInfo":{"status":"ok","timestamp":1666150439370,"user_tz":-660,"elapsed":3931,"user":{"displayName":"Chaarvi Bansal","userId":"11473149911906912928"}},"outputId":"ac154fd3-0083-45ac-df34-cff1f0c92dba"},"execution_count":90,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0001 train_loss= 122652.38281 train_acc= 0.07891 time= 0.12718\n","Epoch: 0002 train_loss= 27711.88086 train_acc= 0.14682 time= 0.01868\n","Epoch: 0003 train_loss= 12164.87500 train_acc= 0.13777 time= 0.01925\n","Epoch: 0004 train_loss= 28326.54102 train_acc= 0.07891 time= 0.01882\n","Epoch: 0005 train_loss= 33798.60547 train_acc= 0.07891 time= 0.01884\n","Epoch: 0006 train_loss= 23985.89062 train_acc= 0.07891 time= 0.02235\n","Epoch: 0007 train_loss= 13463.92188 train_acc= 0.12430 time= 0.01446\n","Epoch: 0008 train_loss= 11850.89844 train_acc= 0.15630 time= 0.01682\n","Epoch: 0009 train_loss= 13627.68457 train_acc= 0.15778 time= 0.01745\n","Epoch: 0010 train_loss= 15278.48828 train_acc= 0.15456 time= 0.01874\n","Epoch: 0011 train_loss= 15191.28027 train_acc= 0.14408 time= 0.01555\n","Epoch: 0012 train_loss= 13011.88477 train_acc= 0.13500 time= 0.02006\n","Epoch: 0013 train_loss= 9383.86133 train_acc= 0.15616 time= 0.01604\n","Epoch: 0014 train_loss= 6117.11377 train_acc= 0.17936 time= 0.01591\n","Epoch: 0015 train_loss= 4027.95898 train_acc= 0.19632 time= 0.01815\n","Epoch: 0016 train_loss= 3751.60303 train_acc= 0.17776 time= 0.03243\n","Epoch: 0017 train_loss= 4881.24463 train_acc= 0.17223 time= 0.01985\n","Epoch: 0018 train_loss= 6028.80566 train_acc= 0.17482 time= 0.01742\n","Epoch: 0019 train_loss= 6369.69531 train_acc= 0.18930 time= 0.01922\n","Epoch: 0020 train_loss= 5733.75488 train_acc= 0.20549 time= 0.01529\n","Epoch: 0021 train_loss= 4385.64258 train_acc= 0.21803 time= 0.01903\n","Epoch: 0022 train_loss= 2912.80957 train_acc= 0.22643 time= 0.01806\n","Epoch: 0023 train_loss= 2035.61035 train_acc= 0.21161 time= 0.01845\n","Epoch: 0024 train_loss= 2063.91357 train_acc= 0.21135 time= 0.02473\n","Epoch: 0025 train_loss= 2276.64917 train_acc= 0.20041 time= 0.02837\n","Epoch: 0026 train_loss= 2516.44727 train_acc= 0.17272 time= 0.01986\n","Epoch: 0027 train_loss= 2369.65405 train_acc= 0.19964 time= 0.01841\n","Epoch: 0028 train_loss= 1856.13611 train_acc= 0.23169 time= 0.01843\n","Epoch: 0029 train_loss= 1414.83496 train_acc= 0.27963 time= 0.02430\n","Epoch: 0030 train_loss= 1107.51050 train_acc= 0.29983 time= 0.01901\n","Epoch: 0031 train_loss= 1016.70612 train_acc= 0.34688 time= 0.01640\n","Epoch: 0032 train_loss= 1090.80127 train_acc= 0.36073 time= 0.01826\n","Epoch: 0033 train_loss= 1203.89734 train_acc= 0.38431 time= 0.02197\n","Epoch: 0034 train_loss= 1273.66650 train_acc= 0.40730 time= 0.01981\n","Epoch: 0035 train_loss= 1227.53601 train_acc= 0.42532 time= 0.01692\n","Epoch: 0036 train_loss= 969.47223 train_acc= 0.44510 time= 0.01934\n","Epoch: 0037 train_loss= 641.75763 train_acc= 0.47015 time= 0.01656\n","Epoch: 0038 train_loss= 386.63696 train_acc= 0.49826 time= 0.01748\n","Epoch: 0039 train_loss= 317.26248 train_acc= 0.52769 time= 0.01750\n","Epoch: 0040 train_loss= 388.44186 train_acc= 0.54434 time= 0.01827\n","Epoch: 0041 train_loss= 519.49225 train_acc= 0.55112 time= 0.01681\n","Epoch: 0042 train_loss= 582.06622 train_acc= 0.56799 time= 0.01703\n","Epoch: 0043 train_loss= 558.22406 train_acc= 0.57809 time= 0.01707\n","Epoch: 0044 train_loss= 510.51645 train_acc= 0.56580 time= 0.01740\n","Epoch: 0045 train_loss= 421.99887 train_acc= 0.57180 time= 0.01918\n","Epoch: 0046 train_loss= 339.60031 train_acc= 0.57038 time= 0.01992\n","Epoch: 0047 train_loss= 275.16791 train_acc= 0.54640 time= 0.01714\n","Epoch: 0048 train_loss= 241.07991 train_acc= 0.52909 time= 0.01731\n","Epoch: 0049 train_loss= 275.07388 train_acc= 0.49579 time= 0.02231\n","Epoch: 0050 train_loss= 283.78281 train_acc= 0.49348 time= 0.01984\n","Epoch: 0051 train_loss= 239.08047 train_acc= 0.52096 time= 0.01756\n","Epoch: 0052 train_loss= 201.86200 train_acc= 0.53810 time= 0.01725\n","Epoch: 0053 train_loss= 156.43921 train_acc= 0.56129 time= 0.01686\n","Epoch: 0054 train_loss= 151.77925 train_acc= 0.58763 time= 0.01863\n","Epoch: 0055 train_loss= 203.04190 train_acc= 0.59238 time= 0.01959\n","Epoch: 0056 train_loss= 232.34044 train_acc= 0.58286 time= 0.02088\n","Epoch: 0057 train_loss= 207.23207 train_acc= 0.60125 time= 0.01796\n","Epoch: 0058 train_loss= 190.40945 train_acc= 0.59938 time= 0.01929\n","Epoch: 0059 train_loss= 156.14973 train_acc= 0.58159 time= 0.01804\n","Epoch: 0060 train_loss= 112.01385 train_acc= 0.56329 time= 0.01758\n","Epoch: 0061 train_loss= 83.09321 train_acc= 0.54469 time= 0.01695\n","Epoch: 0062 train_loss= 130.00339 train_acc= 0.49193 time= 0.01664\n","Epoch: 0063 train_loss= 109.74747 train_acc= 0.50630 time= 0.01721\n","Epoch: 0064 train_loss= 116.55151 train_acc= 0.51530 time= 0.01465\n","Epoch: 0065 train_loss= 130.83542 train_acc= 0.51916 time= 0.01640\n","Epoch: 0066 train_loss= 111.97223 train_acc= 0.52123 time= 0.01754\n","Epoch: 0067 train_loss= 81.46722 train_acc= 0.53802 time= 0.01898\n","Epoch: 0068 train_loss= 113.55975 train_acc= 0.53002 time= 0.02203\n","Epoch: 0069 train_loss= 89.51458 train_acc= 0.56725 time= 0.01405\n","Epoch: 0070 train_loss= 80.74855 train_acc= 0.57509 time= 0.01914\n","Epoch: 0071 train_loss= 99.59421 train_acc= 0.55818 time= 0.02726\n","Epoch: 0072 train_loss= 94.56729 train_acc= 0.55894 time= 0.01636\n","Epoch: 0073 train_loss= 68.84733 train_acc= 0.57351 time= 0.01730\n","Epoch: 0074 train_loss= 74.14975 train_acc= 0.57402 time= 0.01694\n","Epoch: 0075 train_loss= 66.99010 train_acc= 0.57968 time= 0.01891\n","Epoch: 0076 train_loss= 69.58933 train_acc= 0.55987 time= 0.01661\n","Epoch: 0077 train_loss= 70.68088 train_acc= 0.57157 time= 0.01828\n","Epoch: 0078 train_loss= 72.69379 train_acc= 0.57157 time= 0.02759\n","Epoch: 0079 train_loss= 67.83825 train_acc= 0.58005 time= 0.02183\n","Epoch: 0080 train_loss= 61.13038 train_acc= 0.57423 time= 0.02067\n","Epoch: 0081 train_loss= 65.29134 train_acc= 0.54356 time= 0.01746\n","Epoch: 0082 train_loss= 49.95474 train_acc= 0.57229 time= 0.01635\n","Epoch: 0083 train_loss= 46.84949 train_acc= 0.60538 time= 0.01484\n","Epoch: 0084 train_loss= 54.57037 train_acc= 0.60761 time= 0.01710\n","Epoch: 0085 train_loss= 49.84441 train_acc= 0.60510 time= 0.01769\n","Epoch: 0086 train_loss= 53.63678 train_acc= 0.58795 time= 0.01678\n","Epoch: 0087 train_loss= 47.49760 train_acc= 0.60560 time= 0.01949\n","Epoch: 0088 train_loss= 47.00191 train_acc= 0.60232 time= 0.01729\n","Epoch: 0089 train_loss= 44.56664 train_acc= 0.59417 time= 0.01658\n","Epoch: 0090 train_loss= 40.16691 train_acc= 0.59422 time= 0.02086\n","Epoch: 0091 train_loss= 41.37927 train_acc= 0.57443 time= 0.01920\n","Epoch: 0092 train_loss= 38.43930 train_acc= 0.58505 time= 0.02227\n","Epoch: 0093 train_loss= 40.97006 train_acc= 0.57664 time= 0.01622\n","Epoch: 0094 train_loss= 39.14148 train_acc= 0.58275 time= 0.02250\n","Epoch: 0095 train_loss= 35.22002 train_acc= 0.58958 time= 0.01786\n","Epoch: 0096 train_loss= 40.56214 train_acc= 0.58633 time= 0.01830\n","Epoch: 0097 train_loss= 37.18377 train_acc= 0.60435 time= 0.01778\n","Epoch: 0098 train_loss= 41.19367 train_acc= 0.60442 time= 0.02121\n","Epoch: 0099 train_loss= 40.76285 train_acc= 0.59580 time= 0.01555\n","Epoch: 0100 train_loss= 42.54465 train_acc= 0.59975 time= 0.01525\n","Epoch: 0101 train_loss= 38.35051 train_acc= 0.59278 time= 0.02054\n","Epoch: 0102 train_loss= 33.90998 train_acc= 0.61283 time= 0.01788\n","Epoch: 0103 train_loss= 49.22976 train_acc= 0.60295 time= 0.01760\n","Epoch: 0104 train_loss= 32.42354 train_acc= 0.60135 time= 0.01859\n","Epoch: 0105 train_loss= 35.53850 train_acc= 0.59020 time= 0.01616\n","Epoch: 0106 train_loss= 49.86257 train_acc= 0.57309 time= 0.01817\n","Epoch: 0107 train_loss= 31.66153 train_acc= 0.59253 time= 0.01817\n","Epoch: 0108 train_loss= 41.43900 train_acc= 0.60559 time= 0.01688\n","Epoch: 0109 train_loss= 32.10470 train_acc= 0.60995 time= 0.01769\n","Epoch: 0110 train_loss= 31.30306 train_acc= 0.61382 time= 0.01981\n","Epoch: 0111 train_loss= 33.07898 train_acc= 0.59742 time= 0.01329\n","Epoch: 0112 train_loss= 27.78547 train_acc= 0.62161 time= 0.01464\n","Epoch: 0113 train_loss= 28.81998 train_acc= 0.61895 time= 0.01850\n","Epoch: 0114 train_loss= 28.42321 train_acc= 0.61173 time= 0.01804\n","Epoch: 0115 train_loss= 24.26804 train_acc= 0.61866 time= 0.01792\n","Epoch: 0116 train_loss= 26.21606 train_acc= 0.61133 time= 0.01836\n","Epoch: 0117 train_loss= 27.71833 train_acc= 0.62581 time= 0.01666\n","Epoch: 0118 train_loss= 26.55937 train_acc= 0.61704 time= 0.01975\n","Epoch: 0119 train_loss= 27.19484 train_acc= 0.62670 time= 0.01899\n","Epoch: 0120 train_loss= 21.58913 train_acc= 0.64625 time= 0.01527\n","Epoch: 0121 train_loss= 29.98959 train_acc= 0.63860 time= 0.01413\n","Epoch: 0122 train_loss= 21.86949 train_acc= 0.65552 time= 0.01917\n","Epoch: 0123 train_loss= 25.27420 train_acc= 0.64144 time= 0.02015\n","Epoch: 0124 train_loss= 24.97429 train_acc= 0.63485 time= 0.01781\n","Epoch: 0125 train_loss= 20.28173 train_acc= 0.64347 time= 0.01886\n","Epoch: 0126 train_loss= 24.57212 train_acc= 0.62507 time= 0.01983\n","Epoch: 0127 train_loss= 19.56358 train_acc= 0.62973 time= 0.01650\n","Epoch: 0128 train_loss= 23.11626 train_acc= 0.61970 time= 0.01623\n","Epoch: 0129 train_loss= 21.04245 train_acc= 0.62619 time= 0.01806\n","Epoch: 0130 train_loss= 21.37255 train_acc= 0.62895 time= 0.01943\n","Epoch: 0131 train_loss= 21.32721 train_acc= 0.61362 time= 0.01820\n","Epoch: 0132 train_loss= 19.07027 train_acc= 0.62467 time= 0.02568\n","Epoch: 0133 train_loss= 21.13764 train_acc= 0.63633 time= 0.02075\n","Epoch: 0134 train_loss= 20.89509 train_acc= 0.63945 time= 0.01651\n","Epoch: 0135 train_loss= 19.51672 train_acc= 0.63403 time= 0.02284\n","Epoch: 0136 train_loss= 21.69504 train_acc= 0.61853 time= 0.01547\n","Epoch: 0137 train_loss= 18.23881 train_acc= 0.64570 time= 0.01548\n","Epoch: 0138 train_loss= 24.05794 train_acc= 0.65542 time= 0.01690\n","Epoch: 0139 train_loss= 19.65157 train_acc= 0.64437 time= 0.01744\n","Epoch: 0140 train_loss= 20.70507 train_acc= 0.63469 time= 0.01871\n","Epoch: 0141 train_loss= 19.65926 train_acc= 0.62713 time= 0.01528\n","Epoch: 0142 train_loss= 22.22411 train_acc= 0.64199 time= 0.01490\n","Epoch: 0143 train_loss= 18.91072 train_acc= 0.64321 time= 0.01895\n","Epoch: 0144 train_loss= 21.98838 train_acc= 0.62838 time= 0.01417\n","Epoch: 0145 train_loss= 21.66117 train_acc= 0.63444 time= 0.01645\n","Epoch: 0146 train_loss= 14.71198 train_acc= 0.65558 time= 0.01703\n","Epoch: 0147 train_loss= 26.40453 train_acc= 0.64796 time= 0.02326\n","Epoch: 0148 train_loss= 15.91492 train_acc= 0.67209 time= 0.02037\n","Epoch: 0149 train_loss= 21.05328 train_acc= 0.66408 time= 0.01657\n","Epoch: 0150 train_loss= 22.20115 train_acc= 0.65375 time= 0.01699\n","Epoch: 0151 train_loss= 15.95776 train_acc= 0.64450 time= 0.01639\n","Epoch: 0152 train_loss= 18.51966 train_acc= 0.64213 time= 0.02912\n","Epoch: 0153 train_loss= 24.02038 train_acc= 0.62418 time= 0.01534\n","Epoch: 0154 train_loss= 16.82045 train_acc= 0.64629 time= 0.01689\n","Epoch: 0155 train_loss= 17.61730 train_acc= 0.65384 time= 0.01575\n","Epoch: 0156 train_loss= 18.35320 train_acc= 0.66339 time= 0.01860\n","Epoch: 0157 train_loss= 18.80317 train_acc= 0.66641 time= 0.01756\n","Epoch: 0158 train_loss= 16.47960 train_acc= 0.66232 time= 0.02223\n","Epoch: 0159 train_loss= 21.11960 train_acc= 0.63369 time= 0.01898\n","Epoch: 0160 train_loss= 13.88293 train_acc= 0.64384 time= 0.01727\n","Epoch: 0161 train_loss= 18.34911 train_acc= 0.64303 time= 0.01604\n","Epoch: 0162 train_loss= 15.36060 train_acc= 0.64379 time= 0.01400\n","Epoch: 0163 train_loss= 17.25667 train_acc= 0.63947 time= 0.01723\n","Epoch: 0164 train_loss= 14.08709 train_acc= 0.64250 time= 0.01774\n","Epoch: 0165 train_loss= 19.40110 train_acc= 0.63689 time= 0.01805\n","Epoch: 0166 train_loss= 13.62312 train_acc= 0.66590 time= 0.01774\n","Epoch: 0167 train_loss= 15.66281 train_acc= 0.66588 time= 0.01410\n","Epoch: 0168 train_loss= 16.24746 train_acc= 0.67122 time= 0.01784\n","Epoch: 0169 train_loss= 13.02816 train_acc= 0.67326 time= 0.01467\n","Epoch: 0170 train_loss= 14.89097 train_acc= 0.66743 time= 0.01502\n","Epoch: 0171 train_loss= 17.96191 train_acc= 0.66092 time= 0.01912\n","Epoch: 0172 train_loss= 13.20812 train_acc= 0.67378 time= 0.01443\n","Epoch: 0173 train_loss= 14.39565 train_acc= 0.67199 time= 0.01543\n","Epoch: 0174 train_loss= 15.09166 train_acc= 0.67073 time= 0.02198\n","Epoch: 0175 train_loss= 12.80046 train_acc= 0.67890 time= 0.02065\n","Epoch: 0176 train_loss= 12.15828 train_acc= 0.67435 time= 0.01928\n","Epoch: 0177 train_loss= 16.84215 train_acc= 0.65852 time= 0.01361\n","Epoch: 0178 train_loss= 13.22727 train_acc= 0.66492 time= 0.01494\n","Epoch: 0179 train_loss= 14.02169 train_acc= 0.66182 time= 0.02089\n","Epoch: 0180 train_loss= 15.26906 train_acc= 0.66576 time= 0.01775\n","Epoch: 0181 train_loss= 12.21260 train_acc= 0.66567 time= 0.01515\n","Epoch: 0182 train_loss= 13.79644 train_acc= 0.64706 time= 0.02204\n","Epoch: 0183 train_loss= 16.80635 train_acc= 0.61426 time= 0.02511\n","Epoch: 0184 train_loss= 12.73894 train_acc= 0.64272 time= 0.02249\n","Epoch: 0185 train_loss= 13.11435 train_acc= 0.66828 time= 0.01794\n","Epoch: 0186 train_loss= 14.42125 train_acc= 0.66939 time= 0.01815\n","Epoch: 0187 train_loss= 13.03552 train_acc= 0.67399 time= 0.02116\n","Epoch: 0188 train_loss= 11.92877 train_acc= 0.67675 time= 0.02234\n","Epoch: 0189 train_loss= 15.00372 train_acc= 0.66328 time= 0.01578\n","Epoch: 0190 train_loss= 13.77260 train_acc= 0.66769 time= 0.01689\n","Epoch: 0191 train_loss= 12.46291 train_acc= 0.67038 time= 0.01581\n","Epoch: 0192 train_loss= 15.31644 train_acc= 0.68117 time= 0.01722\n","Epoch: 0193 train_loss= 10.92983 train_acc= 0.68202 time= 0.01705\n","Epoch: 0194 train_loss= 12.64637 train_acc= 0.67670 time= 0.02039\n","Epoch: 0195 train_loss= 15.11442 train_acc= 0.66104 time= 0.01618\n","Epoch: 0196 train_loss= 11.50268 train_acc= 0.68242 time= 0.01979\n","Epoch: 0197 train_loss= 12.40001 train_acc= 0.67590 time= 0.01738\n","Epoch: 0198 train_loss= 12.81356 train_acc= 0.66611 time= 0.01991\n","Epoch: 0199 train_loss= 11.84151 train_acc= 0.66495 time= 0.01800\n","Epoch: 0200 train_loss= 11.99183 train_acc= 0.66462 time= 0.01665\n","Optimization Finished!\n"]}]},{"cell_type":"code","source":["emb.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rNoyuRwXmkWv","executionInfo":{"status":"ok","timestamp":1666150464518,"user_tz":-660,"elapsed":258,"user":{"displayName":"Chaarvi Bansal","userId":"11473149911906912928"}},"outputId":"3e256fb8-b970-4a2b-e4e0-54909e3554e5"},"execution_count":91,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(438, 8)"]},"metadata":{},"execution_count":91}]},{"cell_type":"code","source":["pd.DataFrame(emb).to_csv(\"/content/drive/MyDrive/Thesis_5_1/data/DDR-emb-gae-8.csv\")"],"metadata":{"id":"brRRfmpVo_P2","executionInfo":{"status":"ok","timestamp":1666150476980,"user_tz":-660,"elapsed":283,"user":{"displayName":"Chaarvi Bansal","userId":"11473149911906912928"}}},"execution_count":92,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"bJgagkbKpMDN"},"execution_count":null,"outputs":[]}]}